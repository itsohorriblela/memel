# 为什么需要消息队列？

## 异步处理

削峰，解耦

## 限流

使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。


# 如何选择消息队列？

## Rabbit MQ

优点：轻量级、容易部署和使用、支持多种客户端开发语言、支持灵活的路由配置  
缺点：对消息堆积的支持并不好、性能和吞吐量较差、使用 Erlang 语言编写，比较难进行二次开发

## Rocket MQ

优点：性能好、稳定可靠、有活跃的中文社区、使用 Java 开发，容易进行二次开发、特点响应快  
缺点：兼容性较差

## Kafka

优点：兼容性极好、设计上大量使用了批量和异步的思想，有超高的性能  
缺点：由于 "先攒一波再一起处理" 的设计，时延较高，不太适合在线业务场景

## 总结

消息队列并不是你将要构建的主角之一，对消息队列的功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，建议使用 RabbitMQ。

如果系统使用消息队列的主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性是我们需要的。

如果需要的是处理海量的数据，像收集日志、监控信息或是前端的埋点这类数据，或是应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合的消息队列。


# 不同消息队列的消息模型

## 队列模型

队列，先进先出

## 发布订阅模型

在发布-订阅模型中，消息的发送者称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。

发布 - 订阅模型与队列模型之间最大的区别就是解决了 一份消息数据能不能被消费多次的问题 。

## RabbitMQ 的消息模型

RabbitMQ 是少数依然坚持使用队列模型的产品之一。在 RabbitMQ 中，Exchange 位于生产者和队列之间，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange ，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。

同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。

## RocketMQ 的消息模型

RocketMQ 使用的是标准的发布 - 订阅模型。

由于 "请求 - 确认" 机制的存在，在消费端为了保证消息的有序性，某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则，也就是说，每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。

为了解决这个问题，RocketMQ 在主题下面增加了队列的概念，每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。

RocketMQ 中订阅者的概念是通过消费组（Consumer Group）来实现的，不同消费组订阅同一主题的时候，每个消费组都会消费一份完整的消息，不同消费组之间消费进度彼此不受影响。

消费组中包含多个消费者，同一组内的消费者之间是竞争关系，每个消费者负责消费组内的一部分消息。

因为消息会被不同消费组进行多次消费，所以消费完的消息并不会被立即删除，而是由 RocketMQ 为每一个消费组在每个队列上维护一个消费位置，这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。

## kafka的消息模型

Kafka 的消息模型与 RocketMQ 是完全一致的，唯一的区别是：在 Kafka 中，队列对应的名称是 "分区（Partition）" ,其含义和功能没有任何区别。



# rabbit MQ 和 kafka 的对比

RabbitMQ和Kafka都是流行的消息队列系统，它们都可以用于构建分布式系统中的消息传递机制。
虽然它们都可以用于相似的场景，但它们之间仍然存在一些重要的区别。

1. 数据处理方式不同

RabbitMQ是一个传统的AMQP消息队列，它使用队列来存储和传递消息，并通过消息持久化和队列持久化机制，将消息和队列持久化到磁盘中。RabbitMQ在消息传递方面的优点是它可以提供高可靠性和持久性，可以确保消息不会丢失，即使在处理过程中发生故障。


Kafka则是一个分布式流处理平台，它使用分布式日志来存储和传递消息。它支持高吞吐量和低延迟的实时数据流处理，适合处理大量的数据流。Kafka的消息处理方式是通过分区和复制来保证高可用性和可靠性。

2. 性能方面

由于Kafka是专门为流处理而设计的，因此它在处理大量数据时比RabbitMQ更快。Kafka的高吞吐量和低延迟使其适合于需要实时数据处理的场景。RabbitMQ适合于需要较少的消息传递和较高的可靠性的场景。


3. 可用性

Kafka和RabbitMQ都是可扩展的，并且可以部署在分布式环境中，但是，它们在可用性方面有所不同。RabbitMQ在节点故障时可以提供高可用性，但是需要使用专门的集群插件和负载均衡器来实现。Kafka则通过复制和分区来保证高可用性，即使某些节点失败，也可以继续提供服务。


4. 数据存储方式

RabbitMQ使用磁盘来存储消息，这意味着它可以存储大量的消息并且不会丢失数据。
Kafka则将消息存储在内存中的日志中，这使得Kafka在处理大量数据时非常快，但也意味着它可能会在节点故障时丢失一些数据。为了避免数据丢失，Kafka会定期将消息写入磁盘中的日志文件。这样即使在节点故障时，也可以从磁盘中的日志文件恢复数据。


5. 使用场景

RabbitMQ适合于需要高可靠性和持久性的消息传递场景，异步任务处理，系统解耦，流量削峰，日志收集，实时通信，金融交易、电子商务等。

而Kafka适合于需要高吞吐量和低延迟的实时数据处理场景，追求高吞吐量，适合产生大量数据的互联网服务的数据收集业务，但是分区存储的topic无法保证消息的有序性，由于其消费消息采用提交偏移量机制，导致一旦偏移量提交出现问题，就会导致消息丢失，或者重复消费问题。
实时日志分析、大屏看板统计、公交实时数据、实时热点文章分值计算。



# 消息队列可能会产生哪些问题？ 如何解决？

## 消息丢失

### 检测消息丢失

可以利用消息队列的有序性来验证是否有消息丢失。原理很简单，在 Producer 端，给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。

如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的。也就是说，收到的消息的序号必然是上一条消息的序号 + 1，如果检测到不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。

如果是分布式系统中则需要注意，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。

如果系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。

Consumer 实例的数量最好和分区数量一致，做好 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。


### 确保消息可靠传递

一条消息从生产到消费完成这个过程，可以划分为三个阶段

- 生产阶段：消息在 Producer 创建出来，经过网络传输发送到 Broker 端。

- 存储阶段：消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。

- 消费阶段：Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。


#### 生产阶段

在生产阶段，消息队列通过最常用的 请求确认机制 ，来保证消息的可靠性传递：当代码调用发送消息时，消息队列的客户端会把消息发送到 Broker ，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，就代表完成了一次正常消息的发送

只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有的消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。

#### 存储阶段

一般来说，只要 Broker 正常运行，就不会出现消息丢失的问题，当然如果 Broker 出现了故障，仍然是有可能会丢失消息的。

如果对消息的可靠性要求极高，可以通过 配置 Broker 参数 来避免因为宕机而丢失消息。

对于单个节点的 Broker ，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。

如果是由多个节点组成的 Broker 集群，需要将 Broker 配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker ，也不会发生消息丢失

#### 消费阶段

消费阶段采用和生产阶段类似的 请求确认机制 来保证消息的可靠传递，客户端从 Broker 拉去消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉取消息时还会返回同一条消息，确保消息不会在网络传输中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。

要注意：不要在收到消息后就立即发送消费确认，而是应当在执行完成所有消费业务逻辑之后，再发送消费确认。


### 重复消息

用幂等性解决重复消息问题

- 利用数据库的唯一约束实现幂等

- 为更新的数据设置前置条件

- 记录并检查操作

实现思路：在执行数据更新操作之前，先检查一下是否执行过这个更新操作


### 消息积压

一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。

1. 限制生产端的生产速度

2. 提高消费者数量

3. 提高消费端的处理能力

4. 耗时长的操作改为异步处理

#### 系统突然消息积压如何分析处理

如果系统在某一时刻，突然开始积压消息并且积压持续上涨，可能会是什么原因呢？

能导致积压突然增加，最粗粒度的原因只有两种：要么是发送变快了，要么是消费变慢了。

我们可以通过消息队列里内置的监控功能，去确定是哪种原因，如果是发送变快了，单位时间内发送的消息增多，比如说赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升性能，唯一的办法是通过扩容消费端实例来提升总体的消费能力。

如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。

还有一种不太常见的情况是，通过监控发现，无论是发送消息的速度还是消费消息的速度都和原来没什么变化，这时候就需要检查一下消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。

如果监控到消费变慢了，就检查一下消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下消费进程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了


# 如何利用消息队列实现分布式事务

首先来看什么是事务，事务就是如果我们需要对若干数据进行更新操作，为了保证这些数据的完整性和一致性，我们希望这些操作 要么都成功，要么都失败 。

一个严格意义上的事务实现，应该具有 4 个属性：原子性、一致性、隔离性、持久性，也就是 ACID 。

大部分的单体关系型数据库都完整的实现了 ACID，但是，对于分布式事务来讲，严格的实现 ACID 这四个特性几乎是不可能的，或者说实现的代价太大，大到我们无法接受。

所以，目前大家所说的分布式事务，更多情况下，是在分布式系统中事务的不完整实现，在实际应用中，比较常见的分布式事务实现有 2PC（二阶段提交）、TCC（Try-Confirm-Cancel）和事务消息，每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息适用的场景主要是那些需要异步更新数据，并且对实时性要求不太高的场景。

## 消息队列如何实现分布式事务

Kafka 和 RocketMQ 都提供了事务相关功能。

首先，生产者在消息队列上开启一个事务，然后向消息服务器发送一个 "半消息"，所谓 "半消息" ，就是说该消息内容是完整的，但在事务提交之前，对消费者是不可见的。

半消息发送成功之后，生产者就可以执行本地事务了，根据本地事务执行成功与否决定提供或回滚消息，如果事务执行成功，那就提交事务消息，消费者就可以消费这条半消息了，如果事务执行失败，那就回滚事务，消费者系统就不会收到这条消息了。这样就基本实现了 "要么都成功，要么都失败" 的一致性要求。

其实在这个流程中还有一个问题未解决，那就是提交事务消息的时候也可能会失败，对于这个问题，RocketMQ 和 Kafka 给出了两种不同的解决方案。

Kafka 的解决方案比较简单粗暴，直接抛出异常，由用户决定怎样处理。可以在业务代码中反复重试提交，直到成功，也可以通过恢复生产者的状态进行补偿。


## RocketMQ分布式事务实现

在 RocketMQ 中是通过增加了事务反查的机制来解决事务消息提交失败的问题。

如果生产者在提交或回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去生产者上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。


# 使用消息队列如何保证顺序消费？

消息队列中的若干消息如果是对同一个数据进行操作，这些操作具有前后的关系，必须要按前后的顺序执行，否则就会造成数据异常。


## rabbit MQ

一个Queue对应一下Consumer，把需要保证顺序的message都发送到一个Queue当中，关闭autoack，prefetchCount=1，每次只消费一条信息，处理过后进行手工ack，然后接收下一条message，只是由一个Consumer进行处理。

多数业务场景下，可以做局部顺序，创建多个队列，同一业务id的消息发送到同一个消息队列，这样队列数增加，消费者数量也会增加了。

拆分多个Queue，每个Queue一个Consumer，就是多一些Queue而已。


## kafka

确保顺序消息发送到同一个partition，一个topic，对于一个partition使用一个consumer，内部单线程消费。






