# 关系型数据库设计理论

## 数据库设计范式
第一范式： 属性不可分。    
第二范式： 每个非主属性完全依赖于键码。  
第三范式： 非主属性不传递依赖于键码。  

## 数据库系统核心知识点  

### 锁

MySQL 中提供了两种封锁粒度: 行级锁以及表级锁。应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。但是加锁需要消耗资源，锁的各种操作(包括获取锁、释放锁、以及检查锁状态)都会增加系统开销。因此封锁粒度越小，系统开销就越大。在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。

#### 读写锁

写锁： X锁、排他锁  
读锁： S锁、共享锁  

#### 意向锁 Intention Lock  

使用意向锁(Intention Locks)可以更容易地支持多粒度封锁。
在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

为了避免DML在执行时，加的行锁与表锁的冲突，在innoDB加入意向锁，使得表锁不用在检查每行数据是否加锁，使得意向锁来减少表锁的检查

意向锁都是表锁

意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定:
	一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；  
	一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。  

任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁；  
S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。  


上了行级X锁后，行级X锁不会因为有别的事务上了IX而堵塞，一个mysql是允许多个行级X锁同时存在的，只要他们不是针对相同的数据行。


#### 封锁协议  

一级封锁协议： 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。
可以解决修改丢失问题。  

二级封锁协议： 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。
可以解决脏读问题。  

三级封锁协议： 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。
可以解决不可重复读问题。  


#### 两段锁协议  

加锁和解锁分为两个阶段进行。

#### 多版本并发控制  MVCC

多版本并发控制(Multi-Version Concurrency Control, MVCC)是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。#

数据库隐式字段：

DB_ROW_ID 6byte, 隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引  
DB_TRX_ID 6byte, 最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务    
IDDB_ROLL_PTR 7byte, 回滚指针，指向这条记录的上一个版本（存储于rollback segment里）    
DELETED_BIT 1byte, 记录被更新或删除并不代表真的删除，而是删除flag变了  


##### Read View

事务执行SQL语句时，产生的读视图。实际上在innodb中，每个SQL语句执行前都会得到一个Read View。主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”

- m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。   
- min_limit_id:表示在生成Read View时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。  
- max_limit_id:表示生成Read View时，系统中应该分配给下一个事务的id值。  
- creator_trx_id: 创建当前Read View的事务ID  
  
1. 如果数据事务ID trx_id < min_limit_id，表明生成该版本的事务在生成Read View前，已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。

2. 如果trx_id>= max_limit_id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。

3. 如果 min_limit_id =<trx_id< max_limit_id，需要分3种情况讨论
	（1）.如果m_ids包含trx_id,则代表Read View生成时刻，这个事务还未提交，但是如果数据的trx_id等于creator_trx_id的话，表明数据是自己生成的，因此是可见的。  
	（2）如果m_ids包含trx_id，并且trx_id不等于creator_trx_id，则Read View生成时，事务未提交，并且不是自己生产的，所以当前事务也是看不见的；  
	（3）.如果m_ids不包含trx_id，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。  

读到的数据版本中会有一个删除标记位，用来区分是否已经被删除。

对于删除的情况可以认为是update的特殊情况，delete数据的时候会将版本上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时将该条记录的头信息（record header ）里的（deleted_flag）标记位写上true，表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录，如果deleted_flag标记位为true，意味着数据已经被删除，则不会被返回。


快照读： 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。

当前读： 读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。



##### MVCC如何实现读已提交和可重复读

创建 Read View的时机不同

RC隔离级别下，是每个快照读都会生成并获取最新的Read View；当一个事务开始时，它会为每个查询创建一个一致的快照，并只读取已提交的数据版本。其他事务的修改不会被读取

而在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View。

#### MVCC如何实现读未提交和串行化

- 读未提交  

InnoDB允许事务读取其他事务尚未提交的数据。在这个级别下，InnoDB不会对读取的数据进行加锁或记录版本信息。

事务开始时会创建一个一致的快照，并在整个事务期间使用这个快照来读取数据。

- 串行化

这是最高的隔离级别，它通过完全串行化事务来避免并发访问。它确保事务之间的读写操作完全互斥，避免了任何形式的并发冲突。在这个级别下，InnoDB会对读取的数据进行共享锁，以及对写入的数据进行排他锁，从而实现事务的串行执行。




#### NEXT-Key LOCKs

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读(REPEATABLE READ)隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。#

Next-key Locks是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。


# 有用的SQL命令

## CONCAT
在 MySQL 中，CONCAT 函数用于将多个字符串连接在一起。它接受两个或多个参数，并返回这些参数连接后的字符串。
SELECT CONCAT('My name is ', first_name, ' ', last_name) AS full_name FROM users;  

## EXPLAIN
EXPLAIN 是 MySQL 数据库提供的一个关键字，用于分析和优化查询语句的执行计划。通过 EXPLAIN，您可以获取有关查询的详细信息，了解 MySQL 在执行查询时所采取的操作和优化策略。

要使用 EXPLAIN，只需在查询语句前加上 EXPLAIN 关键字，然后执行该语句。MySQL 将返回一个描述查询执行计划的结果集，其中包含以下重要的列：

id: 表示查询中每个操作的标识符，主要用于连接操作。  
select_type: 描述查询的类型，例如简单查询、联接查询、子查询等。  
table: 指示查询涉及的表。  
type: 表示每个表的访问方式，例如全表扫描、索引扫描、范围扫描等。  
possible_keys: 表示可能用于查询的索引。  
key: 表示实际选择的索引。  
key_len: 表示索引使用的字节数。  
ref: 表示索引的比较列。  
rows: 表示查询扫描的行数估计值。  
Extra: 提供其他与查询相关的附加信息，如排序操作、临时表使用等。  


# MYSQL定时任务  EVENT事件

自MySQL5.1.6起，增加了一个非常有特色的功能 - 事件调度器（Event Scheduler），可以用做定时执行某些特定任务（例如：删除记录、数据统计报告、数据备份等等），来取代原先只能由操作系统的计划任务来执行的工作。
值得一提的是MySQL的事件调度器可以精确到每秒钟执行一个任务，而操作系统的计划任务（如：Linux的cron）只能精确到每分钟执行一次。对于一些对数据实时性要求比较高的应用（例如：股票、赔率、比分等）就非常适合。

事件有时也可以称为临时触发器（temporal triggers），因为事件调度器是基于特定时间周期触发来执行某些任务，而触发器（Triggers）是基于某个表所产生的事件触发的，区别也就在这里。

# MYSQL存储过程 PROCEDURE

　　一组可编程的函数，是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行。



# 坑 

## between

mysql的between包含边界值

## NULL

in匹配的时候用的是=  
not in 匹配的时候用的是 <>
NULL只能用is null或者is not null来判定

## 大小写

MySQL在Linux下数据库名、表名、列名、别名大小写规则是这样的：
1、数据库名与表名是严格区分大小写的；  
2、表的别名是严格区分大小写的；  
3、列名与列的别名在所有的情况下均是忽略大小写的；  
4、字段内容默认情况下是大小写不敏感的。  

InnoDB在创建表时可以设置 COLLATE utf8mb4_bin指定大小写敏感  
`show collation where charset = 'utf8mb4';`
ci结尾为大小写不敏感，bin结尾的是大小写敏感  

## 高并发下更新丢失

两个事务同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了。这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来。

- 第一类丢失更新： A事务撤销时，把已经提交的B事务的更新数据覆盖了。SQL标准中未对此做定义，所有数据库都已解决了第一类丢失更新的问题。

- 第二类丢失更新

A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失。

解决方案

1. 调整SQL语句，将更新赋值逻辑改为“c=c+x”形式，其中c为要更新的字段，x为增量值。这种方式能确保累加值不会被覆盖。

2. 悲观锁：利用redis分布式锁

3. 乐观锁： 增加版本概念，若版本冲突则回退

## 唯一索引

创建唯一索引的字段，都不能允许为null，否则mysql的唯一性约束可能会失效。  


# 基础知识 

## mysql架构

### server层
	
#### 连接器： 

负责建立与客户端的连接，mysql有自己的数据库连接池，每个连接都会有对应线程处理。

#### 分析器： 

进行语法分析， 生成解析树。    

#### 优化器： 

适配联合索引、提前终止查询、in查询先排序再采用二分法查找。  
查询优化器内部具体怎么实现的我们不需要是关心，我需要知道的是 MySQL 会帮我去使用他自己认为的最好的方式去优化这条 SQL 语句，并生成一条条的执行计划，比如你创建了多个索引，MySQL 会依据成本最小原则来选择使用对应的索引，这里的成本主要包括两个方面, IO 成本和 CPU 成本  

1. IO 成本: 即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本就是 1。所以 IO 的成本主要和页的大小有关  

2. CPU 成本：将数据读入内存后，还要检测数据是否满足条件和排序等 CPU 操作的成本，显然它与行数有关，默认情况下，检测记录的成本是 0.2。MySQL 优化器 会计算 「IO 成本 + CPU」 成本最小的那个索引来执行


#### 执行器： 与存储引擎交互  

从执行器开始调用存储引擎接口做了哪些事情呢？

1. 准备更新一条 SQL 语句  
2. MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中  
3. 在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中  
4. innodb 会在 Buffer Pool 中执行更新操作  
5. 更新后的数据会记录在 redo log buffer 中  
6. MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中 刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置 
	值为 0 表示不刷入磁盘  
	值为 1 表示立即刷入磁盘  
	值为 2 表示先刷到 os cache  
7. myslq 重启的时候会将 redo 日志恢复到缓冲池中

其实 MySQL 在提交事务的时候，不仅仅会将 redo log buffer 中的数据写入到redo log 文件中，同时也会将本次修改的数据记录到 bin log文件中，同时会将本次修改的bin log文件名和修改的内容在bin log中的位置记录到redo log中，最后还会在redo log最后写入 commit 标记，这样就表示本次事务被成功的提交了。

MySQL 会有一个后台线程，它会在某个时机将我们Buffer Pool中的脏数据刷到 MySQL 数据库磁盘中，这样就将内存和数据库的数据保持统一了。



### 存储引擎层

	myisam  
	innodb  	

### 系统文件层
	
	日志文件  
	配置文件  
	数据文件  

## InnoDB引擎介绍  

### 内存结构

	缓冲池BP （Buffer Pool）
	mysql使用buffer pool缓存池来管理内存， Buffer Pool （缓冲池）是 InnoDB 存储引擎中非常重要的内存结构，顾名思义，缓冲池其实就是类似 Redis 一样的作用，起到一个缓存的作用。  
	BP中有三种链表结构，free list表示空闲缓冲区，lru list为正在使用的缓冲区，flush list表示需要刷新到磁盘的缓冲区。

	写缓冲区CB  (Change Buffer)
	在进行DML操作时，如果BP没有其相应的Page数据，并不会立刻将磁盘页加载到缓冲池，而是在CB记录缓冲变更，等未来数据被读取时，会先进行磁盘读取，然后再从CB中读取信息合并，最终载入BufferPool中。 不过，仅适用于非唯一普通索引页，如果在索引设置唯一性，在进行修改时，InnoDB必须要做唯一性校验，因此必须查询磁盘，做一次IO操作。会直接将记录查询到BufferPool中，然后在缓冲池修改，不会在ChangeBuffer操作。   

	日志缓冲区Log Buffer  
	日志缓冲区，用来保存要写入磁盘上log文件（Redo/Undo）的数据，日志缓冲区的内容定期刷新到磁盘log文件中。日志缓冲区满时会自动将其刷新到磁盘。


### 磁盘结构  
	
	表空间 Tablespaces  

	数据字典  

	双写缓冲区  

	redo log

	重做日志是一种基于磁盘的数据结构，用于在崩溃恢复期间更正不完整事务写入的数据，默认情况下，重做日志在磁盘上由两个名为ib_logfile0和ib_logfile1的文件物理表示

    undo log

    用于例外情况时回滚事务。撤消日志属于逻辑日志，根据每行记录进行记录。撤消日志存在于系统表空间、撤消表空间和临时表空间中

### 线程模型  

	IO thread
	purge Thread  回收已分配的undo page  
	page Cleaner Thread  将脏数据刷新到磁盘  
	Master Thread 主线程，负责调度其他各线程  


## 日志系统  

### undo log

	数据库事务开始之前，会将要修改的记录存放到 Undo 日志里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志，撤销未提交事务对数据库产生的影响. undo log 由后台的purge thread 进行回收  


	作用： 

	1. 实现事务的原子性: 事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 Undo Log 中的备份将数据恢复到事务开始之前的状态
	2. 实现多版本并发控制（MVCC）: 事务未提交之前，Undo Log保存了未提交之前的版本数据，Undo Log 中的数据可作为数据旧版本快照供其他并发事务进行快照读

### redo log  

	redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置) 环状结构，固定大小。

	新增或更新记录时先记录到redo log中，并更新内存，空闲时再写入磁盘，如果内存页中的数据与磁盘的数据不一致则称这个内存页为脏页，mysql偶尔会抖一下，是在刷脏页（flush）写入是采用的是*两阶段提交*  

	刷脏页的场景： 
		1.redo log 满了  
		2.系统内存不够时  
		3. 系统空闲时  
		4. mysql正常关闭时  

### bin log

	mysql server层自己的日志，是逻辑日志。主要应用场景为主从复制、数据恢复。


## 索引

### 按存储结构

B+树索引   哈希索引  全文索引  空间数据索引（R-Tree） 

#### B+树索引

一般B+树是由多个页组成的多层级结构，每个页16Kb，对于主键索引来说，最末级的叶子结点放行数据，非叶子结点放的则是索引信息（主键id和页号），用于加速查询。
只有在叶子和索引结点都满了的情况下，B+树才会考虑加入一层新的结点。要把三层B+树塞满，那大概需要2kw左右的数据。


B+树只在末级叶子结点处放数据表行数据，而B树则会在叶子和非叶子结点上都放。
同样数据量的情况下，使用B+树的磁盘IO要小于B树的磁盘IO。


跳表是否新增层数，纯粹靠随机函数，根本不关心前后上下结点。

##### 所以为什么mysql用B+树而不是用跳表呢？  

- 存放同样量级的数据，B+树的高度比跳表的要少，如果放在mysql数据库上来说，就是磁盘IO次数更少，因此B+树查询更快。  
- 而针对写操作，B+树需要拆分合并索引数据页，跳表则独立插入，并根据随机函数确定层数，没有旋转和维持平衡的开销，因此跳表的写入性能会比B+树要好。

##### redis为什么用跳表而不是用B+树呢？  

redis支持多种数据结构，里面有个有序集合，也叫ZSET。内部实现就是跳表。

- redis 是纯纯的内存数据库。
进行读写数据都是操作内存，跟磁盘没啥关系，因此也不存在磁盘IO了，所以层高就不再是跳表的劣势了。
并且前面也提到B+树是有一系列合并拆分操作的，换成红黑树或者其他AVL树的话也是各种旋转，目的也是为了保持树的平衡。
而跳表插入数据时，只需要随机一下，就知道自己要不要往上加索引，根本不用考虑前后结点的感受，也就少了旋转平衡的开销。


### 按应用层次

普通索引  唯一索引  主键索引  联合索引  前缀索引  全文索引  

- 联合索引： MySQL可以使用多个字段同时建立一个索引,叫做联合索引。mysql索引的底层结构就是一个二叉树，联合索引也是一样，它的非叶子节点中存的就不只是一个列，是索引的所有列，并且它的排序就是根据索引列的先后顺序来排的。
使用联合索引要满足最左前缀规则。


## 按索引键值类型

主键索引  辅助索引  

## 按数据存储和索引键值关系

聚集索引  非聚集索引


## 事务和锁

### 隔离级别

	读未提交  读已提交  可重复读  串行化  

### MVCC
	
	在MySQL中，MVCC只在读取已提交（Read Committed）和可重复读（Repeatable Read）两个事务级别下有效。其是通过Undo日志中的版本链和ReadView一致性视图来实现的。MVCC就是在多个事务同时存在时，SELECT语句找寻到具体是版本链上的哪个版本，然后在找到的版本上返回其中所记录的数据的过程。利用了Copy on Write的思想


	Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)  

### 锁

#### innoDB锁的释放时机

lock通常在事务commit或是rollback之后才会释放

innoDB的行锁是可重入的


#### 全局锁

#### 表级锁

#### 行锁

	只有通过索引条件检索数据时，InnoDB才会使用行级锁，否则会使用表级锁(索引失效，行锁变表锁)  

	死锁： 两个事务互相等待对方释放锁。指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象  
	死锁产生条件： 
	1. 互斥条件：一个资源每次只能被一个进程使用  
	2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放  
	3. 不剥夺条件：进程已获得的资源，在没有使用完之前，不能强行剥夺  
	4. 循环等待条件：多个进程之间形成的一种互相循环等待的资源的关系  

  
	如何解决死锁： 
	1.设置锁超时时间innodb_lock_wait_timeout，默认50s   2.发起死锁检测。 innodb_deadlock_detect设置为on  

	间隙锁： 

	隙锁（Gap Lock）是Innodb在可重复读（RR）提交下为了解决幻读问题时引入的锁机制，幻读在“当前读”才会出现，幻读产生的原因是行锁只能锁住行，对于新插入的记录这个动作，要更新的是记录之间的间隙。


## 集群架构  

### 主从架构

	主从同步  

	主要涉及三个线程: binlog 线程、I/O 线程和 SQL 线程。  
	binlog 线程 : 负责将主服务器上的数据更改写入二进制日志中。  
	I/O 线程 : 负责从主服务器上读取二进制日志，并写入从服务器的中继日志中。  
	SQL 线程 : 负责读取中继日志并重放其中的 SQL 语句。   


	读写分离  

	读写分离能提高性能的原因在于:
	主从服务器负责各自的读和写，极大程度缓解了锁的争用；  
	从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；  
	增加冗余，提高可用性。  

	双主模式  

	主备切换


#### 主从同步相关的问题

	步骤

	1.执行更新sql语句。
   2.主库写成功时，binlog会更新。
   3.主库binlog dump 线程将binlog的更新部分发给从库
   4.从库io线程收到binlog更新部分，然后写入到relay log中
   5.从库sql线程读取relay log内容，重放执行sql，最后主从一致。


relay log 作用

relay log的作用就类似于一个中间层，**主库是多线程并发写的，从库的sql线程是单线程串行执行的，所以这两边的生产和消费速度肯定不同。**当主库发的binlog消息过多时，从库的relay log可以起到暂存主库数据的作用，接着从库的sql线程再慢慢消费这些relay log数据，这样既不会限制主库发消息的速度，也不会给从库造成过大压力。


- 主从延迟

果你有写数据后就立马要读数据的场景，要是此时读的是从库，很有可能会读到更新前的旧数据，如果你对数据一致性有较高要求，这种时候建议读主库。   

- 有没有可能从库已经读到新值了，主库读到旧值？

有可能， 可重复隔离级别。

		



## InnoDB在RR级别下如何解决幻读

在RR的隔离级别下，Innodb使用MVCC和next-key locks解决幻读，MVCC解决的是普通读（快照读）的幻读，next-key locks解决的是当前读情况下的幻读。 

### 当前读

所谓当前读，指的是加锁的select(S或者X), update, delete等语句。在RR的事务隔离级别下，数据库会使用next-key locks来锁住本条记录以及索引区间。 

### 普通读

因为普通读是不会加锁的读，故不会有next-key locks的使用，解决幻读的手段是MVCC  


而每一个事务在启动的时候，都有一个唯一的递增的版本号。每开启一个新事务，事务的版本号就会递增。 

默认的隔离级别（REPEATABLE READ）下，增删查改变成了这样：  

- SELECT

读取创建版本小于当前事务版本号，并且删除标记为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的  

- INSERT

将当前事务的版本号保存至行的创建版本号  

- UPDATE

新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除标记记为已删除。

- DELETE

将当前事务的版本号保存至行，删除标记记为已删除。



## 最左前缀原则

	左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到  
	查询的时候如果两个条件都用上了，但是顺序不同，如 city= xx and name ＝xx，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。  
	由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。  

    原理： 构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。  


## char、varchar、text的选择

1. char长度固定，char(n)中的n表示字符数，最大长度是255个字符, 即每条数据占用等长字节空间；适合用在身份证号码、手机号码等定。

2. varchar可变长度，varchar(n)中的n表示最大字符数，最大空间是65535个字节, 可以设置最大长度；适合用在长度可变的属性。

3. text不设置长度， 当不知道属性的最大长度时，适合用text。


## 两阶段提交

1. 写入redo log, 置redo log状态为prepare
2. 写bin log
3. 修改redo log状态为commit

bin log是否完整是事务是否成功的标志

那为什么还需要第三步呢？
如果没有第三步，在判断redo_log和bin_log是否一致时需要全量对比，性能差。

- redo log : 固定大小、循环写的日志文件

- bin log : 无限大小、追加写的日志文件

一条数据首先被写入内存，之后再被写入磁盘。
redo log就是用来记录写入内存但未刷盘的日志，已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。  
已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。  


当数据库 crash 后，如何恢复未刷盘的数据到内存中？
根据 redo log 和 binlog 的两阶段提交，未持久化的数据分为几种情况：

1. change buffer 写入，redo log 虽然做了 fsync 但未 commit，binlog 未 fsync 到磁盘，这部分数据丢失。

2. change buffer 写入，redo log fsync 未 commit，binlog 已经 fsync 到磁盘，先从 binlog 恢复 redo log，再从 redo log 恢复 change buffer。

3. change buffer 写入，redo log commit 和 binlog 都已经 fsync，直接从 redo log 里恢复。


# MYSQL数据类型中长度的含义

## 字符串类型

主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。

VARCHAR 会保留字符串末尾的空格，而 CHAR 会删除。 


CHAR(10) VARCHAR(10)  n表示可容纳的最大字符数

## 整数类型

TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。

INT(5) n表示显示位宽，基本没用。

## 浮点数类型

FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。

DECIMAL(M, D) M代表最大位数，D表示小数点右侧的位数。  
DECIMAL是以字符串形式存储的，所以会占用M个字节。

## 选择标识符identifier  

整数类型通常是标识列的最佳选择，因为它们很快并且可以使用AUTO_INCREMENT。 如果可能，应该避免使用字符串类型作为标识列，因为它们很耗空间，并且比数字类型慢。 对于完全随机的字符串也需要多加注意，例如MD5(),SHA1()或者UUID()产生的字符串。这些函数生成的新值会任意分布在很大的空间内，这会导致INSERT以及一些SELECT语句变得很慢：  
	1. 因为插入值会随机的写入到索引的不同位置，所以使得INSERT语句更慢。这会导致页分裂、磁盘随机访问。  
	2. SELECT语句会变的更慢，因为逻辑上相邻的行会分布在磁盘和内存的不同地方。  
	3. 随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的局部性原理失效。  


# 分库分表  

- mysql在单表数据过大时，查询性能会变差，因此当数据量变得巨大时，需要考虑水平分表。

- mysql水平分表后，对于非分片键字段的查询会有读扩散的问题，可以用普通索引列作分片键建一个新表，先查新表拿到id后再回到原表再查一次原表。这本质上是借鉴了倒排索引的思路。

- 如果想要支持更多维度的查询，可以监听mysql的binlog，将数据写入到es，提供近实时的查询能力。

- 当然，用tidb替换mysql也是个思路。tidb属实是个好东西。




# SQL语法基础  

## 注释

```
# 注释
SELECT *
FROM mytable; -- 注释
/* 注释1
   注释2 */
```

## 连接join  

笛卡尔积：  A , B 返回笛卡尔积  

内连接： inner join  

自然连接： natural join   自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。

外链接： outer join 


## 语句优化  

- 负向查询不能使用索引  

- 前导%模糊不能使用索引  

- 字段默认值不要为null，否则肯能会带来一些非预期的结果。

- 字段上计算不能命中索引 

- 不要让数据库帮我们做强制转换，否则会导致全表扫描。 

- 需要进行join的字段两表的字段类型要相同，否则不会命中索引。


 
# 更新一条数据的全过程  

1. 首先执行器根据 MySQL 的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中  
2. 在数据被缓存到缓存池的同时，会写入 undo log 日志文件  
3. 更新的动作是在 BufferPool 中完成的，同时会将更新后的数据添加到 redo log buffer 中  
4. 完成以后就可以提交事务，在提交的同时会做以下三件事 
	将redo log buffer中的数据刷入到 redo log 文件中  
	将本次操作记录写入到 bin log文件中  
	将 bin log 文件名字和更新内容在 bin log 中的位置记录到redo log中，同时在 redo log 最后添加 commit  
标记至此表示整个更新事务已经完成


# 为什么读多写少要用MyIsam比较好？  

如果是读多写少的项目,可以考虑使用 MyISAM,MYISAM 索引和数据是分开的，而且其索引是压缩的，可以更好地利用内存。所以它的查询性能明显优于 INNODB。压缩后的索引也能节约一些磁盘空间。MYISAM 拥有全文索引的功能，这可以极大地优化 LIKE 查询的效率。


# 主键为自增ID的好处  

- MYSQL数据页大小固定为16K  
- 数据页内，以及数据页之间，数据主键id都是从小到大排序的  
- 由于数据页大小固定了是16k，当我们需要插入一条新的数据，数据页会被慢慢放满，当超过16k时，这个数据页就有可能会进行分裂。  
- 针对B+树叶子节点，如果主键是自增的，那它产生的id每次都比前一次要大，所以每次都会将数据加在B+树尾部，B+树的叶子节点本质上是双向链表，查找它的首部和尾部，时间复杂度O(1)。而如果此时最末尾的数据页满了，那创建个新的页就好。  
- 如果主键不是自增的，插入时就需要查找对应的页位置， 如果目标页正好满了，就需要进行页分裂， 降低性能。
- MYSQL默认主键 RAW_ID (隐藏列还有trx_id-记录数据行被哪个事务修改过, roll_pointer-指向数据行的上一个版本undo_log)  


# 同样都是拿10条数据，查第一页和第一百页的查询速度是一样的吗？

mysql查询中 limit 1000,10 会比 limit 10 更慢。原因是 limit 1000,10 会取出1000+10条数据，并抛弃前1000条，这部分耗时更大

当offset过大，会引发深度分页问题，目前不管是mysql还是es都没有很好的方法去解决这个问题。只能通过限制查询数量或分批获取的方式进行规避。


# MYSQL查询慢的原因梳理

## 索引不符合预期  

## 数据库连接数过少  

## buffer pool 太小 


# mysql单表数据推荐最大多少

2kw
单表最大值还受主键大小和磁盘大小限制。
超过2kw会导致磁盘IO次数变多，影响性能。


# 回表查询

select * 通常需要一次回表查询才能查出其他字段。

回表，顾名思义就是回到表中，也就是先通过普通索引（我们自己建的索引不管是单列索引还是联合索引，都称为普通索引）扫描出数据所在的行，再通过行主键ID 取出索引中未包含的数据。所以回表的产生也是需要一定条件的，如果一次索引查询就能获得所有的select 记录就不需要回表，如果select 所需获得列中有其他的非索引列，就会发生回表动作。即基于非主键索引的查询需要多扫描一棵索引树。

Mysql回表指的是在InnoDB存储引擎下，二级索引查询到的索引列，如果需要查找所有列的数据，则需要到主键索引里面去取出数据。这个过程就称为回表。因为行的数据都是存在主键B+tree的叶子节点里面，二级索引的B+树叶子节点都是存放的(索引列,主键)

简单来说，回表就是 MySQL 要先查询到主键索引，然后再用主键索引定位到数据

## 聚簇索引

InnoDB聚簇索引的叶子节点存储行记录， 即主键索引。

主键索引的叶子节点存储的是一行完整的数据

## 非聚簇索引

主键索引之外的就是非聚簇索引，非聚簇索引又叫辅助索引或者二级索引

非主键索引的叶子节点存储的是主键值。叶子节点不包含记录的全部数据，非主键的叶子节点除了用来排序的 key 还包含一个书签（bookmark），其中存储了聚簇索引的 key

## 覆盖索引避免回表

覆盖索引就是指索引中包含了查询中的所有字段，这种情况下就不需要再进行回表查询




