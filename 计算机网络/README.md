# 浏览器发起一次HTTPS请求的过程详解

HTTPS会对HTTP的URL和Request Body都进行加密

## 构建请求

## 查找浏览器缓存

## DNS解析

1. 查询浏览器DNS缓存

2. 查询操作系统DNS缓存

3. 读取hosts文件

4. 请求DNS服务器

## TCP三次握手

## TLS四次握手

### 客户端发送client Hello ,消息包含TLS版本以及client random随机字符串

### 服务端发送server Hello, 消息包含数字证书以及server random随机字符串，证书通过CA私钥加密。

### 客户端验证证书，通过CA公钥解密。（CA公钥不多，一般直接配置到操作系统或浏览器里。）

1. 检查数字签名

2. 验证证书链

3. 检查证书有效期

4. 检查证书的撤回状态

### 客户端发送 pre_master secret字符串，利用服务端证书里的公钥加密 （加密算法如RSA)

### 服务端利用服务端私钥解密获得pre_master secret

### 客户端和服务端利用client random 、server random、 pre_master secret 生成共享密钥

### 客户端就绪，发送共享密钥加密过的finished

### 服务端就绪， 发送共享密钥加密过的finished

## 达成安全通信，通过共享密钥加密传输数据

## 四次挥手


# 非对称加密与对称加密啊  

因为非对称加密慢，对称加密相对来说快一些。

# 为什么要用三个随机数？ 直接用pre_master secret不行吗？

确实，就算没有另外两个，也并不影响加密功能。之所以还要两个随机数，是因为只有单个 pre_master_key随机性不足，多次随机的情况下有可能出来的秘钥是一样的。但如果再引入两个随机数，就能大大增加"会话秘钥"的随机程度，从而保证每次HTTPS通信用的会话秘钥都是不同的。




# 网站带WWW和不带有什么区别

	本质上两者的域名是不同的，建议将没有www的域名重定向的www的域名。统一有助于将权重集中在一个域名上。


# sse 与 web socket

## sse (server-sent events)  


SSE 是基于 HTTP 的服务器推送技术，使用简单的长轮询机制。  
客户端通过在浏览器中创建 EventSource 对象来与服务器建立 SSE 连接。  
服务器可以实时地将事件流数据推送到客户端，客户端通过监听事件进行处理。  
SSE 适用于单向的服务器到客户端的推送，服务器可以持续地向客户端发送事件流数据。  
SSE 只能使用 HTTP 协议，不能使用其他协议。


## web scoket

WebSocket 是一种全双工的通信协议，通过在客户端和服务器之间建立持久连接实现双向通信。   
客户端通过在浏览器中创建 WebSocket 对象来与服务器建立 WebSocket 连接。  
WebSocket 连接使用 WebSocket 协议，不依赖于 HTTP，可以使用其他协议（如 ws:// 或 wss://）。  
WebSocket 提供了一种双向通信的机制，客户端和服务器可以随时发送消息给对方。  
WebSocket 适用于需要实时双向通信的应用，如聊天应用、协作编辑、实时数据更新等。    

## 对比

SSE 适用于服务器向客户端单向推送事件流的场景，通常用于实时的通知、实时更新等应用。  
WebSocket 适用于双向通信的场景，允许客户端和服务器之间进行实时的双向数据交换，通常用于实时聊天、实时协作等应用。  
SSE 使用基于 HTTP 的长轮询机制，而 WebSocket 使用独立的协议。  
SSE 对于支持的浏览器比较广泛，但功能较为有限；WebSocket 需要更高级的浏览器支持，但提供了更丰富的功能。  
根据应用需求，可以选择 SSE 或 WebSocket 来实现实时通信，具体取决于通信模式和功能要求。
    

## IP地址分类  

	A类： 1.0.0.0 ～ 127.255.255.255 
	B类： 128.0.0.0 ～ 191.255.255.255  
	C类： 192.0.0.0 ～ 223.255.255.255  
	D类： 224.0.0.0 ～ 239.255.255.255  特殊用途  
	E类： 240.0.0.0 ～ 255.255.255.255  暂时保留  

### 私有地址

在IPv4地址中预留了3个IP地址段，作为私有地址，共家庭、企业、学校等内部组网使用。  
10.0.0.0 ～ 10.255.255.255  
172.16.0.0 ～ 172.31.255.255  
192.168.0.0 ～ 192.168.255.255  
在局域网里的多个设备通过公网ip访问互联网时，可以通过NAT地址转换，像作者说的地址转换表。通过这张地址转换表，路由器会将你的内网ip连同端口号一起转换为外网ip和端口号，这样就可以访问你要通信的主机，来达到通信目的。  


# NAT

NAT设备，全称Network Address Translation，网络地址转换。  

NAT负责将内网IP-PORT与公网IP-PORT做一个映射转换。

# 内网穿透 

没有什么是加中间层不能解决的，如果有，那就再加一层

因为NAT的存在，我们只能从内网主动发起连接，否则NAT设备不会记录相应的映射关系，没有映射关系也就不能转发数据。
所以我们就在公网上加一台服务器x，并暴露一个访问域名，再让内网的服务主动连接服务器x，这样NAT路由器上就有对应的映射关系。接着，所有人都去访问服务器x，服务器x将数据转发给内网机器，再原路返回响应，这样数据就都通了。这就是所谓的内网穿透。

# NAT打洞

通过一个中间server在双方的NAT上留下映射关系，来打通连接。

linux内核中唯一标识一个网络连接是通过五元组  （传输协议，源IP，目的IP，源端口，目的端口）


# 用了CDN一定比不用CDN快吗？   

用了CDN时，未命中CDN缓存导致回源，就会比不用的时候更慢。

解决方法： 刷新预热

CDN最大的优势在于，对于来自世界各地的用户，它可以就近分配CDN节点获取数据，并且多次重复获取同一个文件数据的时候，有缓存加速的作用。如果你的服务和对象存储都在内网，并且文件数据也不太会有重复使用的可能性，那其实没必要接入cdn。


# 世界上只有13组DNS服务器，如果国外卡我们脖子咋办 ？

虽然根域只有13个IP，但不代表只有13台服务器，准确的说，应该是十三组服务器，每组服务器都共用同一个IP，国内已经有非常多的镜像服务器，利用任播技术，只要能就近访问到其中一台就行了。
我们只要镜像一份国外的DNS域名服务器信息到国内机房里。我们就不再需要请求国外服务器了。


# 电脑如何获得自己的IP？

DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）
向某个管IP分配的服务器，也就是DHCP服务器，申请IP地址。

拿到IP后会发三条无偿ARP， 会把IP和mac地址都填好告诉本地网段的所有机器，也可以检查IP是否冲突。


# TCP相对于UDP有哪些方面的不同？

- 超时重传  

- 流量控制 （滑动窗口，发送方与接收方协商一个数据传输窗口大小）

- 拥塞控制， 拥塞控制针对的是整个网络环境数据处理能力的控制。（慢启动算法与拥塞避免）

- 分段，数据包长度大于MSS则会分成N个小于等于MSS的包。而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。

- 乱序重排， 后发的数据包先到是吧，那就先放到专门的乱序队列中，等数据都到齐后，重新整理好乱序队列的数据包顺序后再给到用户，这就是乱序重排机制。

- 面向连接，三次握手，四次挥手。


什么时候UDP会比TCP慢呢？

UDP没有分段，如果数据过大，到了IP层，就会进行分片。此时发生丢包的话，再次重传，就会重传整个大数据包。
在TCP里，它内部会根据MSS的大小分段，这时候进入到IP层之后，每个包大小都不会超过MTU，因此IP层一般不会再进行分片。这时候发生丢包了，只需要重传每个MSS分段就够了。


# http长轮询 

如果我们的HTTP请求将超时设置的很大，比如30s，在这30s内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的长训轮机制。

# websocket

TCP连接的两端，同一时间里，双方都可以主动向对方发送数据。这就是所谓的全双工。

而现在使用最广泛的HTTP1.1，也是基于TCP协议的，同一时间里，客户端和服务器只能有一方主动发数据，这就是所谓的半双工。

websocket 是基于TCP的全双工协议。  

数据包在websocket中被叫做帧。

TCP协议本身就是全双工，但直接使用纯裸TCP去传输数据，会有粘包的"问题"。为了解决这个问题，上层协议一般会用消息头+消息体的格式去重新包装要发的数据。而消息头里一般含有消息体的长度，通过这个长度可以去截取真正的消息体。



# TCP一定不会丢包吗？

TCP只保证数据从A机器的传输层可靠地发到B机器的传输层。

聊天软件还需要将数据从TCP的接收缓冲区里读出来，如果在读出来这一刻，手机由于内存不足或其他各种原因，导致软件崩溃闪退了。这样实际上就会导致消息丢失。

TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果我们还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。


# TCP特点

面向连接，可靠，字节流。

粘包问题。

纯裸TCP是不能直接拿来用的，你需要在这个基础上加入一些自定义的规则，用于区分消息边界。


# HTTP与RPC

HTTP协议（Hyper Text Transfer Protocol），又叫做超文本传输协议。

RPC（Remote Procedure Call），又叫做远程过程调用。它本身并不是一个具体的协议，而是一种调用方式。

虽然大部分RPC协议底层使用TCP，但实际上它们不一定非得使用TCP，改用UDP或者HTTP，其实也可以做到类似的功能。

RPC出现的比HTTP早 

## HTTP和RPC的区别

- 服务发现

在HTTP中，你知道服务的域名，就可以通过DNS服务去解析得到它背后的IP地址，默认80端口。

而RPC的话，就有些区别，一般会有专门的中间服务去保存服务名和IP信息，比如consul或者etcd，甚至是redis。想要访问某个服务，就去这些中间服务去获得IP和端口信息。由于dns也是服务发现的一种，所以也有基于dns去做服务发现的组件，比如CoreDNS。

- 底层连接形式

以主流的HTTP1.1协议为例，其默认在建立底层TCP连接之后会一直保持这个连接（keep alive），之后的请求和响应都会复用这条连接。

而RPC协议，也跟HTTP类似，也是通过建立TCP长链接进行数据交互，但不同的地方在于，RPC协议一般还会再建个连接池，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，可以说非常环保。

由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给HTTP加个连接池，比如go就是这么干的。

- 传输的内容

基于TCP传输的消息，说到底，无非都是消息头header和消息体body。

http一般采用json来做消息体的序列化和反序列化

RPC，因为它定制化程度更高，可以采用体积更小的protobuf或其他序列化协议去保存结构体数据，性能也会更好一些。

# 为什么HTTP和RPC没有互相取代

 很多软件同时支持多端，所以对外一般用HTTP协议，而内部集群的微服务之间则采用RPC协议进行通讯。

 RPC其实比HTTP出现的要早，且比目前主流的HTTP1.1性能要更好，所以大部分公司内部都还在使用RPC。

 HTTP2.0在HTTP1.1的基础上做了优化，性能可能比很多RPC协议都要好，但由于是这几年才出来的，所以也不太可能取代掉RPC。



# socket缓冲区

编程的时候，如果要跟某个IP建立连接，我们需要调用操作系统提供的 socket API。

socket 在操作系统层面，可以理解为一个文件。我们可以对这个文件进行一些方法操作。

用户发送消息的时候写给 send buffer（发送缓冲区）

用户接收消息的时候写给 recv buffer（接收缓冲区）

也就是说一个socket ，会带有两个缓冲区，一个用于发送，一个用于接收。因为这是个先进先出的结构，有时候也叫它们发送、接收队列。

缓冲区可以是阻塞的，也可以是非阻塞的。

## 当发送缓冲区满了： 
- 如果此时 socket 是阻塞的，那么程序会在那干等、死等，直到释放出新的缓存空间，就继续把数据拷进去，然后返回。
- 如果此时 socket 是非阻塞的，程序就会立刻返回一个 EAGAIN 错误信息，意思是 Try again , 现在缓冲区满了，你也别等了，待会再试一次。


## 如果接收缓冲区有数据时，执行close了，会怎么样？

如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发一个RST。
如果接收缓冲区是空的，那么就调用 tcp_send_fin() 开始进行四次挥手过程的第一次挥手。

## 如果发送缓冲区有数据时，执行close了，会怎么样？

socket 缓冲区是个先进先出的队列，这种情况是指内核会等待TCP层安静把发送缓冲区数据都发完，最后再执行 四次挥手的第一次挥手（FIN包）。



# RST包是什么？

我们都是到TCP正常情况下断开连接是用四次挥手，那是正常时候的优雅做法。
但异常情况下，收发双方都不一定正常，连挥手这件事本身都可能做不到，所以就需要一个机制去强行关闭连接。
RST 就是用于这种情况，一般用来异常地关闭一个连接。它在TCP包头中，在收到置了这个标志位的数据包后，连接就会被关闭，此时接收到 RST的一方，一般会看到一个 connection reset 或  connection refused 的报错。


# 连接一个IP不存在的主机会发生什么？

- 如果IP在局域网内，会发送N次ARP请求获得目的主机的MAC地址，同时不能发出TCP握手消息。

- 如果IP在局域网外，会将消息通过路由器发出，但因为最终找不到目的地，触发TCP重试流程， 能发出SYN包。


# 连接一个IP存在但端口不存在的主机

- 不管目的IP是回环地址还是局域网内外的IP地址，目的主机的传输层都会在收到握手消息后，发现端口不正确，发出RST消息断开连接。

- 当然如果目的机器设置了防火墙策略，限制他人将消息发到不对外暴露的端口，那么这种情况，发送端就会不断重试第一次握手。


# ping

ping是应用层命令，其基于网络层的ICMP协议。

虽然ICMP协议和IP协议都属于网络层协议，但其实ICMP也是利用了IP协议进行消息的传输。


# 既然IP层会分片，为什么TCP还要分段？

TCP： 分段

IP： 分片

MSS：Maximum Segment Size 。 TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。

MTU: Maximum Transmit Unit，最大传输单元。 其实这个是由数据链路层提供，为了告诉上层IP层，自己的传输能力是多大。IP层就会根据它进行数据包切分。一般 MTU=1500 Byte。

包越小越不容易丢包，包越大传输效率越高，权衡之下选取了1500

假设有一份数据，较大，且在TCP层不分段，如果这份数据在发送的过程中出现丢包现象，TCP会发生重传，那么重传的就是这一大份数据（虽然IP层会把数据切分为MTU长度的N多个小包，但是TCP重传的单位却是那一大份数据）。

如果TCP把这份数据，分段为N个小于等于MSS长度的数据包，到了IP层后加上IP头和TCP头，还是小于MTU，那么IP层也不会再进行分包。此时在传输路上发生了丢包，那么TCP重传的时候也只是重传那一小部分的MSS段。效率会比TCP不分段时更高。


# TCP粘包

## nagle算法

Nagle算法下发送数据包的条件：
- 如果包长度达到MSS（或含有Fin包），立刻发送，否则等待下一个包到来；如果下一包到来后两个包的总长度超过MSS的话，就会进行拆分发送；

- 等待超时（一般为200ms），第一个包没到MSS长度，但是又迟迟等不到第二个包的到来，则立即发送。

nagle算法会导致粘包

## 关掉nagle算法就不会粘包了吗？

就算关闭 Nagle 算法，接收数据端的应用层没有及时读取 TCP Recv Buffer 中的数据，还是会发生粘包。


## 解决方法

特殊标志分割 +  + 消息长度 + 校验和 


# UDP会粘包吗？

UDP 是基于数据报的传输协议，不会有粘包问题。

基于数据报是指无论应用层交给 UDP 多长的报文，UDP 都照样发送，即一次发送一个报文。至于如果数据包太长，需要分片，那也是IP层的事情，大不了效率低一些。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。而接收方在接收数据报的时候，也不会像面对 TCP 无穷无尽的二进制流那样不清楚啥时候能结束。正因为基于数据报和基于字节流的差异，TCP 发送端发 10 次字节流数据，而这时候接收端可以分 100 次去取数据，每次取数据的长度可以根据处理能力作调整；但 UDP 发送端发了 10 次数据报，那接收端就要在 10 次收完，且发了多少，就取多少，确保每次都是一个完整的数据报。


# IP会粘包吗？
IP层会分片
- 如果消息过长，IP层会按 MTU 长度把消息分成 N 个切片，每个切片带有自身在包里的位置（offset）和同样的IP头信息。
- 各个切片在网络中进行传输。每个数据包切片可以在不同的路由中流转，然后在最后的终点汇合后再组装。
- 在接收端收到第一个切片包时会申请一块新内存，创建IP包的数据结构，等待其他切片分包数据到位。
- 等消息全部到位后就把整个消息包给到上层（传输层）进行处理。

IP 层从按长度切片到把切片组装成一个数据包的过程中，都只管运输，都不需要在意消息的边界和内容，都不在意消息内容了，那就不会有粘包一说了。





